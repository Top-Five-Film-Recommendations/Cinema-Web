#Hadoop分布式环境搭建
##服务器分配
我们综合本次作业的需求以及服务器的情况，选取了三台服务器组建我们的Hadoop集群，其中ip地址为39.100.88.119作为master节点，39.100.129.98，39.100.240.158作为slave节点，并将三台服务器的主机名修改为master、slave1、slave2，在每台服务器上设置ip与主机名的对应
##集群间ssh免密登录
为了方便使用，设置这三台服务器之间的ssh免密
在master节点执行
```shell
ssh-keygen -t rsa
ssh-copy-id -i ~/.ssh/id_rsa.pub master
ssh-copy-id -i ~/.ssh/id_rsa.pub slave1
ssh-copy-id -i ~/.ssh/id_rsa.pub slave2```
##配置java环境
先在master节点执行
###下载jdk,并解压
```shell
tar -xzvf jdk-8u211-linux-x64.tar.gz
mv jdk-8u211-linux-x64.tar.gz /usr/share```
###配置java环境变量
打开 /etc/profile
添加以下内容
```
export JAVA_HOME=/usr/share/jdk1.8.0_211
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
```
使环境变量生效
```shell
source /etc/profile
```
对slave1，slave2执行以上相同操作
scala环境配置与java相同
##安装配置hadoop
下载hadoop2.7.7，解压到/usr/share/，并配置环境变量，与java类似
在hadoop-2.7.7目录下建立tmp，hdfs，hdfs/data，hdfs/name文件夹，分别存储临时文件，集群数据，集群真正的数据，文件系统元数据。
###修改hadoop配置文件
####修改core-site.xml
```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/usr/local/hadoop-2.7.7/tmp</value>
    </property>
    <property>
        <name>io.file.buffer.size</name>
        <value>131072</value>
    </property>
</configuration>
```
>变量fs.defaultFS保存了NameNode的位置，HDFS和MapReduce组件都需要它。这就是它出现在core-site.xml文件中而不是hdfs-site.xml文件中的原因。

####修改marpred-site.xml
```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>master:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>master:19888</value>
    </property>
</configuration>
```
####修改hdfs-site.xml
```xml
<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/share/hadoop-2.7.7/hdfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/usr/share/hadoop-2.7.7/hdfs/data</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:9001</value>
    </property>
    <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
    </property>
</configuration>
```
####修改yarn-site.xml
```xml
<configuration>
        <property>
               <name>yarn.nodemanager.aux-services</name>
               <value>mapreduce_shuffle</value>
        </property>
        <property>
               <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
               <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
               <name>yarn.resourcemanager.address</name>
               <value>master:8032</value>
       </property>
       <property>
               <name>yarn.resourcemanager.scheduler.address</name>
               <value>master:8030</value>
       </property>
       <property>
               <name>yarn.resourcemanager.resource-tracker.address</name>
               <value>master:8031</value>
       </property>
       <property>
               <name>yarn.resourcemanager.admin.address</name>
               <value>master:8033</value>
       </property>
       <property>
               <name>yarn.resourcemanager.webapp.address</name>
               <value>master:8088</value>
       </property>
</configuration>
```
####修改slaves文件中的内容
将localhost设置为slave1 slave2，分两行
###配置slave节点
slave的配置与master一样，只需要把master中已经配好的文件复制到slave节点中即可
```shell
scp -r hadoop-2.7.7 root@slave1:/usr/share
scp -r hadoop-2.7.7 root@slave2:/usr/share
```
##启动hadoop分布式集群
###格式化文件系统
在master节点
```shell
hadoop namenode -format
```
###启动Hadoop集群
```shell
start-all.sh
```
##本地验证hadoop集群
在本地浏览器输入master节点ip:8088
#hbase环境搭建
在hadoop集群的基础上搭建hbase环境
##下载解压配置环境变量
与之前jdk，hadoop一致
##修改相关配置文件
###修改hbase-env.sh
```shell
export JAVA_HOME=/usr/share/jdk1.8.0_211    #Java安装路径
export HBASE_CLASSPATH=/usr/share/hbase-1.3.6    #HBase类路径
export HBASE_MANAGES_ZK=false    #由HBase负责启动和关闭Zookeeper
```
###修改hbase-site.xml
```xml
<property>
    <name>hbase.rootdir</name>
    <value>hdfs://master:9000/hbase</value>
</property>
<property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
</property>
<property>
    <name>hbase.zookeeper.quorum</name>
    <value>slave1,slave2</value>
</property>
```
###修改regionservers
```
slave1
slave2
```
##配置slave节点环境
直接复制修改好的master节点中的hbase文件夹即可
##启动并验证hbase
启动hbase
```shell
start-hbase.sh
```
进入hbase命令行
```shell
hbase shell
```
建立表
```shell
create 'movie','region'
```
建立成功，list能显示
#Spark环境搭建
##下载解压配置环境变量
与之前jdk，hadoop，hbase一致，spark版本为2.3.4
##修改相关配置文件
###修改spark-env.sh
添加java、scala、hadoop、python的路径
在spark-env.sh最后添加
```shell
export JAVA_HOME=/usr/share/jdk1.8.0_211
export SCALA_HOME=/usr/share/scala-2.11.7
export HADOOP_HOME=/usr/share/hadoop-2.7.7
export HADOOP_CONF_DIR=/usr/share/hadoop-2.7.7/etc/hadoop
export SPARK_MASTER_IP=master
export SPARK_WORKER_MEMORY=4g
export PYSPARK_PYTHON=/usr/bin/python3
```
###修改slaves
设置slave节点名称
```
slave1
slave2
```
##配置slave节点环境
直接复制修改好的master节点中的spark文件夹即可
##启动并验证spark集群
在spark的bin目录下./start-all.sh即可启动spark集群
在本地浏览器输入master节点ip:8080 可以看到图形化展示
#MySQL环境搭建
我们将MySQL的环境部署到ip地址为47.92.101.31的服务器上。
##下载并安装MySQL
###下载
首先从官网下载MySQL的Yum Repository
```shell
wget -i -c http://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
```
###安装Yum Repository
```shell
yum -y install mysql80-community-release-el7-3.noarch.rpm
```
###安装MySQL服务器
```shell
yum -y install mysql-community-server
```
##MySQL服务器设置
###密码设置
找到初始密码
```shell
grep "password" /var/log/mysqld.log
```
利用此初始密码进入MySQL shell
修改密码
```shell
ALTER USER 'root'@'localhost' IDENTIFIED BY 'new password';
```
###开启远程访问
0.0.0.0表示开启所有ip的远程访问
```shell
grant all privileges on *.* to 'root'@'0.0.0.0' identified by 'password' with grant option;
```
